{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import random\n",
    "import json\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "import pickle\n",
    "\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_prompt(mask_path,caption):\n",
    "    \n",
    "    caption=caption.replace('.','').strip()\n",
    "    prompt_add=\"Please refer to this description:{}.Modify or correct it.\".format(caption)\n",
    "\n",
    "    return prompt_add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10077/10077 [00:20<00:00, 480.55it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_single_data(prompt,img1,img2,answer):\n",
    "    \"\"\"\n",
    "    构建一个sft块\n",
    "    img1,img2 为路径\n",
    "    \"\"\"\n",
    "    block={\n",
    "            \"conversations\":[\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": prompt\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": answer\n",
    "                }\n",
    "            ],\n",
    "            \"images\": [\n",
    "                img1,\n",
    "                img2\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    return block\n",
    "\n",
    "def get_multi_data(prompt,img1,img2,answer):\n",
    "    \"\"\"\n",
    "    构建一个sft块\n",
    "    img1,img2 为路径\n",
    "    prompt,answer 是字典\n",
    "    \"\"\"\n",
    "    block={\n",
    "            \"conversations\":[\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": prompt['Is']\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": answer['Is']\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": prompt['road']\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": answer['road']\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": prompt['build']\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": answer['build']\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"human\",\n",
    "                    \"value\": prompt['caption']\n",
    "                },\n",
    "                {\n",
    "                    \"from\": \"gpt\",\n",
    "                    \"value\": answer['caption']\n",
    "                }\n",
    "            ],\n",
    "            \"images\": [\n",
    "                img1,\n",
    "                img2\n",
    "            ]\n",
    "        }\n",
    "    \n",
    "    return block\n",
    "\n",
    "def getChageMask(mask_path):\n",
    "    changeMask = Image.open(mask_path)\n",
    "    changeMask = np.array(changeMask)\n",
    "    return changeMask,changeMask.shape\n",
    "\n",
    "def analyze_segmentation_mask(mask,flag=True):\n",
    "    # 目标颜色定义\n",
    "    if flag:\n",
    "        ROAD = [128, 128, 128]\n",
    "        BUILDING = [255, 255, 255]\n",
    "        BACKGROUND = [0, 0, 0]\n",
    "    else:\n",
    "        ROAD = [255, 255,0]\n",
    "        BUILDING = [255, 0, 0]\n",
    "        BACKGROUND = [0, 0, 0]\n",
    "\n",
    "    # 1) 判断掩码图中是否有目标\n",
    "    unique_colors = np.unique(mask.reshape(-1, mask.shape[2]), axis=0)\n",
    "    has_target = any((color != BACKGROUND).all() for color in unique_colors)\n",
    "\n",
    "    # 2) 计算每个类别的目标数量\n",
    "    def count_objects(color):\n",
    "        binary_mask = cv2.inRange(mask, np.array(color), np.array(color))\n",
    "        contours, _ = cv2.findContours(binary_mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "        return len(contours), contours\n",
    "\n",
    "    road_count, road_contours = count_objects(ROAD)\n",
    "    building_count, building_contours = count_objects(BUILDING)\n",
    "\n",
    "    target_counts = {\n",
    "        \"road\": road_count,\n",
    "        \"building\": building_count\n",
    "    }\n",
    "\n",
    "    def simplify_contours(contours, epsilon=5, max_vertices=8):\n",
    "        simplified_contours = []\n",
    "        for contour in contours:\n",
    "            if max_vertices is None:\n",
    "                epsilon_value = epsilon * cv2.arcLength(contour, True) / 100\n",
    "                approx = cv2.approxPolyDP(contour, epsilon_value, True)\n",
    "            else:\n",
    "                # 动态调整epsilon值，直到顶点数小于或等于max_vertices\n",
    "                epsilon_value = epsilon * cv2.arcLength(contour, True) / 100\n",
    "                approx = cv2.approxPolyDP(contour, epsilon_value, True)\n",
    "                while len(approx) > max_vertices and epsilon_value < cv2.arcLength(contour, True):\n",
    "                    epsilon_value += 0.1  # 增加epsilon值\n",
    "                    approx = cv2.approxPolyDP(contour, epsilon_value, True)\n",
    "                    \n",
    "            simplified_contours.append(approx)\n",
    "        return simplified_contours\n",
    "\n",
    "    road_contours_simplified = simplify_contours(road_contours)\n",
    "    building_contours_simplified = simplify_contours(building_contours)\n",
    "\n",
    "    contours = {\n",
    "        \"road\": [contour.reshape(-1, 2).tolist() for contour in road_contours_simplified],\n",
    "        \"building\": [contour.reshape(-1, 2).tolist() for contour in building_contours_simplified]\n",
    "    }\n",
    "\n",
    "    return has_target, target_counts, contours, road_contours_simplified, building_contours_simplified\n",
    "\n",
    "\n",
    "def determine_position(image_shape, contours):\n",
    "    positions = []\n",
    "    height, width = image_shape[:2]\n",
    "    h_third = height / 3\n",
    "    w_third = width / 3\n",
    "\n",
    "    for contour in contours:\n",
    "        M = cv2.moments(contour) \n",
    "        if M['m00'] != 0:\n",
    "            cx = int(M['m10'] / M['m00'])\n",
    "            cy = int(M['m01'] / M['m00'])\n",
    "            \n",
    "            if cx < w_third:\n",
    "                if cy < h_third:\n",
    "                    positions.append('top left corner')    \n",
    "                elif cy < 2 * h_third:\n",
    "                    positions.append('left')\n",
    "                else:\n",
    "                    positions.append('lower left corner')\n",
    "            elif cx < 2 * w_third:\n",
    "                if cy < h_third:\n",
    "                    positions.append('top')\n",
    "                elif cy < 2 * h_third:\n",
    "                    positions.append('center')\n",
    "                else:\n",
    "                    positions.append('lower')\n",
    "            else:\n",
    "                if cy < h_third:\n",
    "                    positions.append('top right corner')\n",
    "                elif cy < 2 * h_third:\n",
    "                    positions.append('right')\n",
    "                else:\n",
    "                    positions.append('lower right corner')\n",
    "        else:\n",
    "            continue\n",
    "    return positions\n",
    "\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "\n",
    "import pickle \n",
    "import json\n",
    "\n",
    "extra_caption=pickle.load(open('/data/coding/datasets/extra/extra_info/extra_caption.pickle','rb'))\n",
    "data=json.load(open('datasets/LEVIR-MCI-dataset/LevirCCcaptions.json','r'))\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "outlist=[]\n",
    "\n",
    "answer_dict={}\n",
    "\n",
    "for i in tqdm(data['images']):\n",
    "\n",
    "    filepath=i['filepath']\n",
    "\n",
    "    filename=i['filename']\n",
    "    answer=i['sentences'][0]['raw']\n",
    "\n",
    "    truth_list=[]\n",
    "    truth_list_all=[]\n",
    "    \n",
    "\n",
    "    for j in i['sentences']:\n",
    "        truth_list.append(j['raw'].replace('.','').strip().split())\n",
    "\n",
    "    out_compute=extra_caption[filename]\n",
    "        \n",
    "\n",
    "    smooth_fn = SmoothingFunction().method1 \n",
    "\n",
    "    bleu_list=[]\n",
    "\n",
    "    for j in truth_list:\n",
    "        bleu_list.append(sentence_bleu([j], out_compute.split(), smoothing_function=smooth_fn,weights=(1,0,0,0))+sentence_bleu([j], out_compute.split(), smoothing_function=smooth_fn,weights=(0,1,0,0))+sentence_bleu([j], out_compute.split(), smoothing_function=smooth_fn,weights=(0,0,1,0))+sentence_bleu([j], out_compute.split(), smoothing_function=smooth_fn,weights=(0,0,0,1)))\n",
    "\n",
    "    argmax=np.argmax(np.array(bleu_list))\n",
    "\n",
    "    answer_dict[filename]=i['sentences'][argmax]['raw'].replace('.','').strip()\n",
    "\n",
    "import pickle\n",
    "\n",
    "data=json.load(open('datasets/LEVIR-MCI-dataset/LevirCCcaptions.json','r'))\n",
    "\n",
    "for i in tqdm(data['images']):\n",
    "\n",
    "    filepath=i['filepath']\n",
    "    filename=i['filename']\n",
    "\n",
    "    mask_path='/data/coding/datasets/LEVIR-MCI-dataset/images/'+filepath+'/label/'+filename\n",
    "    mask,img_shape=getChageMask(mask_path)\n",
    "    has_target, target_counts, contours, road_contours_simplified, building_contours_simplified=analyze_segmentation_mask(mask)\n",
    "\n",
    "    road_loc=determine_position(img_shape,road_contours_simplified)\n",
    "    building_loc=determine_position(img_shape,building_contours_simplified)\n",
    "\n",
    "    a_data=(has_target, target_counts, contours, road_contours_simplified, building_contours_simplified,img_shape,road_loc,building_loc)\n",
    "\n",
    "    with open('/data/coding/datasets/LEVIR-MCI-dataset/extra_info/'+filename,'wb') as f:\n",
    "        pickle.dump(a_data,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10077/10077 [00:20<00:00, 482.09it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "outlist=[]\n",
    "\n",
    "answer_dict={}\n",
    "\n",
    "for i in tqdm(data['images']):\n",
    "\n",
    "    filepath=i['filepath']\n",
    "\n",
    "\n",
    "\n",
    "    filename=i['filename']\n",
    "    answer=i['sentences'][0]['raw']\n",
    "\n",
    "    truth_list=[]\n",
    "    truth_list_all=[]\n",
    "    \n",
    "\n",
    "    for j in i['sentences']:\n",
    "        truth_list.append(j['raw'].replace('.','').strip().split())\n",
    "\n",
    "    out_compute=extra_caption[filename]\n",
    "        \n",
    "\n",
    "    smooth_fn = SmoothingFunction().method1  # 使用平滑方法\n",
    "\n",
    "    bleu_list=[]\n",
    "\n",
    "    for j in truth_list:\n",
    "        bleu_list.append(sentence_bleu([j], out_compute.split(), smoothing_function=smooth_fn,weights=(1,0,0,0))+sentence_bleu([j], out_compute.split(), smoothing_function=smooth_fn,weights=(0,1,0,0))+sentence_bleu([j], out_compute.split(), smoothing_function=smooth_fn,weights=(0,0,1,0))+sentence_bleu([j], out_compute.split(), smoothing_function=smooth_fn,weights=(0,0,0,1)))\n",
    "\n",
    "    #print(bleu_list)\n",
    "    argmax=np.argmax(np.array(bleu_list))\n",
    "\n",
    "    answer_dict[filename]=i['sentences'][argmax]['raw'].replace('.','').strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10077 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10077/10077 [00:01<00:00, 9248.15it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "funtine_data_train_caption=[]           ### change caption\n",
    "funtine_data_train_class=[]             ### 判断是否有变化\n",
    "funtine_data_train_count=[]             ### 计数\n",
    "funtine_data_train_loc=[]               ### 方位\n",
    "funtine_data_train_other_count_road=[]             ###\n",
    "funtine_data_train_other_count_build=[]\n",
    "funtine_data_train_other_loc_road=[] \n",
    "funtine_data_train_other_loc_build=[] \n",
    "funtine_data_train_mutil=[]             ### 多轮对话\n",
    "\n",
    "for i in tqdm(data['images']):\n",
    "\n",
    "    ####\n",
    "    multi_prompt={}\n",
    "    multi_answer={}\n",
    "    ####\n",
    "\n",
    "    filepath=i['filepath']\n",
    "    filename=i['filename']\n",
    "\n",
    "    if filepath=='test':\n",
    "        continue\n",
    "\n",
    "    caption=extra_caption[filename]\n",
    "    ppp=convert_prompt('/data/coding/datasets/extra/'+filename,caption)\n",
    "\n",
    "    img1='/data/coding/datasets/LEVIR-MCI-dataset/images/'+filepath+'/A/'+filename\n",
    "    img2='/data/coding/datasets/LEVIR-MCI-dataset/images/'+filepath+'/B/'+filename\n",
    "\n",
    "    ### change caption\n",
    "\n",
    "    caption_list=[]\n",
    "\n",
    "    if i['changeflag']==0:\n",
    "        answer='the scene is the same as before'\n",
    "\n",
    "        block=get_single_data(ppp+\"Please describe the changes in <image> and <image>\",img1,img2,answer)\n",
    "\n",
    "        funtine_data_train_caption.append(block)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        answer=answer_dict[filename]\n",
    "\n",
    "        block=get_single_data(ppp+\"Please describe the changes in <image> and <image>\",img1,img2,answer) \n",
    "        \n",
    "        funtine_data_train_caption.append(block)\n",
    "\n",
    "      \n",
    "    ######判断是否有改变\n",
    "\n",
    "    if i['changeflag']==1:\n",
    "        answer='Yes'\n",
    "    else:\n",
    "        answer='No'\n",
    "\n",
    "    block=get_single_data(\"Please check if there have been any changes to the roads or buildings in these two images:<image> and <image>. Please answer yes or no.\",img1,img2,answer)\n",
    "\n",
    "    funtine_data_train_class.append(block)\n",
    "    \n",
    "    #if i['changeflag']==1:\n",
    "    multi_prompt['Is']=\"Have there been any changes to the roads and buildings in these two images:<image> and <image>?\"\n",
    "    multi_answer['Is']=answer\n",
    "\n",
    "\n",
    "    \n",
    "    has_target, target_counts, contours, road_contours_simplified, building_contours_simplified,img_shape,road_loc,building_loc=pickle.load(open('/data/coding/datasets/LEVIR-MCI-dataset/extra_info/'+filename,'rb'))\n",
    "\n",
    "    if target_counts['road']!=0:\n",
    "        load_answer=\"There are a total of {} new road here.\".format(target_counts['road'])\n",
    "    else:\n",
    "        load_answer='There are no changes in roads,'\n",
    "\n",
    "    if target_counts['building']!=0:\n",
    "        building_answer=\"There are a total of {} new buildings here.\".format(target_counts['building'])\n",
    "    else:\n",
    "        building_answer='There are no changes in building.'\n",
    "\n",
    "    answer=i['sentences'][0]['raw'].replace('.','').strip()\n",
    "    if i['changeflag']==0:\n",
    "        answer='There are no changes in roads or buildings between the two images'\n",
    "    else:\n",
    "        answer=load_answer+building_answer\n",
    "\n",
    "    block=get_single_data(\"Please determine how many roads and buildings have changed between the two images:<image> and <image>\",img1,img2,answer)\n",
    "\n",
    "    funtine_data_train_count.append(block)\n",
    "\n",
    "\n",
    "    if len(road_loc)!=0:\n",
    "        counter = Counter(road_loc)\n",
    "        load_answer=\"There are a total of {} new road here.There is\".format(len(road_loc))\n",
    "        for j in list(counter.keys()):\n",
    "            load_answer+=\" {} new road located in the {},\".format(counter[j],j)\n",
    "    else:\n",
    "        load_answer='There are no changes in roads,'\n",
    "\n",
    "    if len(building_loc)!=0:\n",
    "        counter = Counter(building_loc)\n",
    "        #print(counter)\n",
    "        building_answer=\"There are a total of {} new buildings here.There is\".format(len(building_loc))\n",
    "        for j in list(counter.keys()):\n",
    "            building_answer+=\" {} new building located in the {},\".format(counter[j],j)\n",
    "        building_answer=building_answer[:-1]+'.' \n",
    "    else:\n",
    "        building_answer='There are no changes in building.'\n",
    "\n",
    "    answer=i['sentences'][0]['raw'].replace('.','').strip()\n",
    "\n",
    "    if i['changeflag']==0:\n",
    "        answer='There are no changes in roads or buildings between the two images'\n",
    "    else:\n",
    "        answer=load_answer+building_answer\n",
    "\n",
    "    block=get_single_data(\"Please identify the location of roads and buildings in the changes in these two images:<image> and <image>\",img1,img2,answer)\n",
    "\n",
    "    funtine_data_train_loc.append(block)\n",
    "\n",
    "    #break\n",
    "\n",
    "    #####  road\n",
    "    if len(road_loc)!=0:\n",
    "        counter = Counter(road_loc)\n",
    "\n",
    "        block_list=[]\n",
    "\n",
    "        funtine_data_train_other_count_road.append(get_single_data(\"How many roads have been changed in these two images:<image> and <image>\",img1,img2,str(len(road_loc))))\n",
    "\n",
    "        block_list.append([\"How many roads have been changed in these two images?\",str(len(road_loc))])\n",
    "\n",
    "        answer=''\n",
    "        for j in list(counter.keys()):\n",
    "            answer+=j+','\n",
    "\n",
    "        answer=answer[:-1]\n",
    "        \n",
    "        funtine_data_train_other_loc_road.append(get_single_data(\"Please tell me where the roads have changed in these two images:<image> and <image>\",img1,img2,answer))\n",
    "\n",
    "        block_list.append([\"Please tell me where the roads have changed in these two images\",answer])\n",
    "\n",
    "        bbb=random.choice(block_list)\n",
    "\n",
    "        multi_prompt['road']=bbb[0]\n",
    "        multi_answer['road']=bbb[1]\n",
    "\n",
    "        \n",
    "    else:\n",
    "        answer='0'\n",
    "\n",
    "        block_list=[]\n",
    "\n",
    "        funtine_data_train_other_count_road.append(get_single_data(\"How many roads have been changed in these two images:<image> and <image>\",img1,img2,answer))\n",
    "\n",
    "        block_list.append([\"How many roads have been changed in these two images?\",answer])\n",
    "\n",
    "        funtine_data_train_other_loc_road.append(get_single_data(\"Please tell me where the roads have changed in these two images:<image> and <image>,if no change please output: No change.\",img1,img2,\"No change\"))\n",
    "\n",
    "        block_list.append([\"Please tell me where the roads have changed in these two images\",\"No change\"])\n",
    "    \n",
    "        bbb=random.choice(block_list)\n",
    "\n",
    "        multi_prompt['road']=bbb[0]\n",
    "        multi_answer['road']=bbb[1]\n",
    "    \n",
    "        ###\n",
    "\n",
    "    #####  building\n",
    "    if len(building_loc)!=0:\n",
    "\n",
    "        block_list=[]\n",
    "\n",
    "        counter = Counter(building_loc)\n",
    "        funtine_data_train_other_count_build.append(get_single_data(\"How many buildings have been changed in these two images:<image> and <image>\",img1,img2,str(len(building_loc))))\n",
    "        \n",
    "        block_list.append([\"How many buildings have been changed in these two images?\",str(len(building_loc))])\n",
    "        \n",
    "        answer=''\n",
    "        for j in list(counter.keys()):\n",
    "            answer+=j+','\n",
    "\n",
    "        answer=answer[:-1]\n",
    "        \n",
    "        funtine_data_train_other_loc_build.append(get_single_data(\"Please tell me where the buildings have changed in these two images:<image> and <image>\",img1,img2,answer))\n",
    "\n",
    "        block_list.append([\"Please tell me where the buildings have changed in these two images\",answer])\n",
    "\n",
    "        bbb=random.choice(block_list)\n",
    "\n",
    "        multi_prompt['build']=bbb[0]\n",
    "        multi_answer['build']=bbb[1]\n",
    "\n",
    "    else:\n",
    "        answer='0'\n",
    "        block_list=[]\n",
    "        funtine_data_train_other_count_build.append(get_single_data(\"How many buildings have been changed in these two images:<image> and <image>\",img1,img2,answer))\n",
    "        block_list.append([\"How many roads have been changed in these two images?\",answer])\n",
    "        funtine_data_train_other_loc_build.append(get_single_data(\"Please tell me where the buildings have changed in these two images:<image> and <image>,if no change please output: No change.\",img1,img2,\"No change\"))\n",
    "\n",
    "        block_list.append([\"Please tell me where the roads have changed in these two images\",\"No change\"])\n",
    "    \n",
    "        bbb=random.choice(block_list)\n",
    "\n",
    "        multi_prompt['build']=bbb[0]\n",
    "        multi_answer['build']=bbb[1]\n",
    "\n",
    "        \n",
    "  \n",
    "    \n",
    "        \n",
    "    multi_prompt['caption']=ppp+'Please describe the changes.'\n",
    "    multi_answer['caption']=answer_dict[filename]\n",
    "\n",
    "    funtine_data_train_mutil.append(get_multi_data(multi_prompt,img1,img2,multi_answer))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('muti_task_data/train_task_data/caption.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(funtine_data_train_caption, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('muti_task_data/train_task_data/binary_class.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(funtine_data_train_class, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('muti_task_data/train_task_data/count_road.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(funtine_data_train_other_count_road, json_file, ensure_ascii=False, indent=4)\n",
    "with open('muti_task_data/train_task_data/count_build.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(funtine_data_train_other_count_build, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('muti_task_data/train_task_data/loc_road.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(funtine_data_train_other_loc_road, json_file, ensure_ascii=False, indent=4)\n",
    "with open('muti_task_data/train_task_data/loc_build.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(funtine_data_train_other_loc_build, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('muti_task_data/train_task_data/mul.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(funtine_data_train_mutil, json_file, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10077/10077 [00:02<00:00, 4431.44it/s]\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "funtine_data_train_caption=[]           ### change caption\n",
    "funtine_data_train_class=[]             ### 判断是否有变化\n",
    "funtine_data_train_count=[]             ### 计数\n",
    "funtine_data_train_loc=[]               ### 方位\n",
    "funtine_data_train_other_count_road=[]             ###\n",
    "funtine_data_train_other_count_build=[]\n",
    "funtine_data_train_other_loc_road=[] \n",
    "funtine_data_train_other_loc_build=[] \n",
    "funtine_data_train_mutil=[]             ### 多轮对话\n",
    "\n",
    "for i in tqdm(data['images']):\n",
    "\n",
    "    ####\n",
    "    multi_prompt={}\n",
    "    multi_answer={}\n",
    "    ####\n",
    "\n",
    "    filepath=i['filepath']\n",
    "    filename=i['filename']\n",
    "\n",
    "    if filepath=='test':\n",
    "        continue\n",
    "\n",
    "    caption=extra_caption[filename]\n",
    "    ppp=convert_prompt('/data/coding/datasets/extra/'+filename,caption)\n",
    "\n",
    "    img1='/data/coding/datasets/LEVIR-MCI-dataset/images/'+filepath+'/A/'+filename\n",
    "    img2='/data/coding/datasets/LEVIR-MCI-dataset/images/'+filepath+'/B/'+filename\n",
    "\n",
    "    ### change caption\n",
    "\n",
    "    caption_list=[]\n",
    "\n",
    "    if i['changeflag']==0:\n",
    "        answer='the scene is the same as before'\n",
    "\n",
    "        block=get_single_data(\"Please describe the changes in <image> and <image>\",img1,img2,answer)\n",
    "\n",
    "        funtine_data_train_caption.append(block)\n",
    "\n",
    "        caption_list.append(answer)\n",
    "\n",
    "    else:\n",
    "        \n",
    "        answer=''\n",
    "        \n",
    "        for idx,j in enumerate(i['sentences']):\n",
    "            answer=j['raw'].replace('.','').strip()\n",
    "\n",
    "            block=get_single_data(\"Please describe the changes in <image> and <image>\",img1,img2,answer) \n",
    "        \n",
    "            funtine_data_train_caption.append(block)\n",
    "\n",
    "            caption_list.append(answer)\n",
    "\n",
    "\n",
    "    ######判断是否有改变\n",
    "\n",
    "    if i['changeflag']==1:\n",
    "        answer='Yes'\n",
    "    else:\n",
    "        answer='No'\n",
    "\n",
    "    block=get_single_data(\"Please check if there have been any changes to the roads or buildings in these two images:<image> and <image>. Please answer yes or no.\",img1,img2,answer)\n",
    "\n",
    "    funtine_data_train_class.append(block)\n",
    "    \n",
    "    #if i['changeflag']==1:\n",
    "    multi_prompt['Is']=\"Have there been any changes to the roads and buildings in these two images:<image> and <image>?\"\n",
    "    multi_answer['Is']=answer\n",
    "\n",
    "    has_target, target_counts, contours, road_contours_simplified, building_contours_simplified,img_shape,road_loc,building_loc=pickle.load(open('/data/coding/datasets/LEVIR-MCI-dataset/extra_info/'+filename,'rb'))\n",
    "\n",
    "    if target_counts['road']!=0:\n",
    "        load_answer=\"There are a total of {} new road here.\".format(target_counts['road'])\n",
    "    else:\n",
    "        load_answer='There are no changes in roads,'\n",
    "\n",
    "    if target_counts['building']!=0:\n",
    "        building_answer=\"There are a total of {} new buildings here.\".format(target_counts['building'])\n",
    "    else:\n",
    "        building_answer='There are no changes in building.'\n",
    "\n",
    "    answer=i['sentences'][0]['raw'].replace('.','').strip()\n",
    "    if i['changeflag']==0:\n",
    "        answer='There are no changes in roads or buildings between the two images'\n",
    "    else:\n",
    "        answer=load_answer+building_answer\n",
    "\n",
    "    block=get_single_data(\"Please determine how many roads and buildings have changed between the two images:<image> and <image>\",img1,img2,answer)\n",
    "\n",
    "    funtine_data_train_count.append(block)\n",
    "\n",
    "\n",
    "    if len(road_loc)!=0:\n",
    "        counter = Counter(road_loc)\n",
    "        load_answer=\"There are a total of {} new road here.There is\".format(len(road_loc))\n",
    "        for j in list(counter.keys()):\n",
    "            load_answer+=\" {} new road located in the {},\".format(counter[j],j)\n",
    "    else:\n",
    "        load_answer='There are no changes in roads,'\n",
    "\n",
    "    if len(building_loc)!=0:\n",
    "        counter = Counter(building_loc)\n",
    "        #print(counter)\n",
    "        building_answer=\"There are a total of {} new buildings here.There is\".format(len(building_loc))\n",
    "        for j in list(counter.keys()):\n",
    "            building_answer+=\" {} new building located in the {},\".format(counter[j],j)\n",
    "        building_answer=building_answer[:-1]+'.' \n",
    "    else:\n",
    "        building_answer='There are no changes in building.'\n",
    "\n",
    "    answer=i['sentences'][0]['raw'].replace('.','').strip()\n",
    "\n",
    "    if i['changeflag']==0:\n",
    "        answer='There are no changes in roads or buildings between the two images'\n",
    "    else:\n",
    "        answer=load_answer+building_answer\n",
    "\n",
    "    block=get_single_data(\"Please identify the location of roads and buildings in the changes in these two images:<image> and <image>\",img1,img2,answer)\n",
    "\n",
    "    funtine_data_train_loc.append(block)\n",
    "\n",
    "    #break\n",
    "\n",
    "    #####  road\n",
    "    if len(road_loc)!=0:\n",
    "        counter = Counter(road_loc)\n",
    "\n",
    "        block_list=[]\n",
    "\n",
    "        funtine_data_train_other_count_road.append(get_single_data(\"How many roads have been changed in these two images:<image> and <image>\",img1,img2,str(len(road_loc))))\n",
    "\n",
    "        block_list.append([\"How many roads have been changed in these two images?\",str(len(road_loc))])\n",
    "\n",
    "        answer=''\n",
    "        for j in list(counter.keys()):\n",
    "            answer+=j+','\n",
    "\n",
    "        answer=answer[:-1]\n",
    "        \n",
    "        funtine_data_train_other_loc_road.append(get_single_data(\"Please tell me where the roads have changed in these two images:<image> and <image>,if no change please output: No change.\",img1,img2,answer))\n",
    "\n",
    "        block_list.append([\"Please tell me where the roads have changed in these two images,if no change please output: No change.\",answer])\n",
    "\n",
    "        bbb=random.choice(block_list)\n",
    "\n",
    "        multi_prompt['road']=bbb[0]\n",
    "        multi_answer['road']=bbb[1]\n",
    "\n",
    "        \n",
    "    else:\n",
    "        answer='0'\n",
    "\n",
    "        block_list=[]\n",
    "\n",
    "        funtine_data_train_other_count_road.append(get_single_data(\"How many roads have been changed in these two images:<image> and <image>\",img1,img2,answer))\n",
    "\n",
    "        block_list.append([\"How many roads have been changed in these two images?\",answer])\n",
    "\n",
    "        funtine_data_train_other_loc_road.append(get_single_data(\"Please tell me where the roads have changed in these two images:<image> and <image>,if no change please output: No change.\",img1,img2,\"No change\"))\n",
    "\n",
    "        block_list.append([\"Please tell me where the roads have changed in these two images,if no change please output: No change.\",\"No change\"])\n",
    "    \n",
    "        bbb=random.choice(block_list)\n",
    "\n",
    "        multi_prompt['road']=bbb[0]\n",
    "        multi_answer['road']=bbb[1]\n",
    "    \n",
    "        ###\n",
    "\n",
    "    #####  building\n",
    "    if len(building_loc)!=0:\n",
    "\n",
    "        block_list=[]\n",
    "\n",
    "        counter = Counter(building_loc)\n",
    "        funtine_data_train_other_count_build.append(get_single_data(\"How many buildings have been changed in these two images:<image> and <image>\",img1,img2,str(len(building_loc))))\n",
    "        \n",
    "        block_list.append([\"How many buildings have been changed in these two images?\",str(len(building_loc))])\n",
    "        \n",
    "        answer=''\n",
    "        for j in list(counter.keys()):\n",
    "            answer+=j+','\n",
    "\n",
    "        answer=answer[:-1]\n",
    "        \n",
    "        funtine_data_train_other_loc_build.append(get_single_data(\"Please tell me where the buildings have changed in these two images:<image> and <image>,if no change please output: No change.\",img1,img2,answer))\n",
    "\n",
    "        block_list.append([\"Please tell me where the buildings have changed in these two images,if no change please output: No change.\",answer])\n",
    "\n",
    "        bbb=random.choice(block_list)\n",
    "\n",
    "        multi_prompt['build']=bbb[0]\n",
    "        multi_answer['build']=bbb[1]\n",
    "\n",
    "    else:\n",
    "        answer='0'\n",
    "        block_list=[]\n",
    "        funtine_data_train_other_count_build.append(get_single_data(\"How many buildings have been changed in these two images:<image> and <image>\",img1,img2,answer))\n",
    "        block_list.append([\"How many roads have been changed in these two images?\",answer])\n",
    "        funtine_data_train_other_loc_build.append(get_single_data(\"Please tell me where the buildings have changed in these two images:<image> and <image>,if no change please output: No change.\",img1,img2,\"No change\"))\n",
    "\n",
    "        block_list.append([\"Please tell me where the roads have changed in these two images,if no change please output: No change.\",\"No change\"])\n",
    "    \n",
    "        bbb=random.choice(block_list)\n",
    "\n",
    "        multi_prompt['build']=bbb[0]\n",
    "        multi_answer['build']=bbb[1]\n",
    "\n",
    "        \n",
    "  \n",
    "    if len(caption_list) != 0:\n",
    "        for kkk in caption_list:\n",
    "            multi_prompt['caption']='Please describe the changes.'\n",
    "            multi_answer['caption']=kkk\n",
    "\n",
    "            funtine_data_train_mutil.append(get_multi_data(multi_prompt,img1,img2,multi_answer))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('muti_task_data/test_task_data/binary_class.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(funtine_data_train_class, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('muti_task_data/test_task_data/count_road.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(funtine_data_train_other_count_road, json_file, ensure_ascii=False, indent=4)\n",
    "with open('muti_task_data/test_task_data/count_build.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(funtine_data_train_other_count_build, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('muti_task_data/test_task_data/loc_road.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(funtine_data_train_other_loc_road, json_file, ensure_ascii=False, indent=4)\n",
    "with open('muti_task_data/test_task_data/loc_build.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(funtine_data_train_other_loc_build, json_file, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open('muti_task_data/test_task_data/mul.json', 'w', encoding='utf-8') as json_file:\n",
    "    json.dump(funtine_data_train_mutil, json_file, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
